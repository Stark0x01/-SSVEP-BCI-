{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12-Class SSVEP Dataset\n",
    "## Classification Using Canonical Correaltion Analysis (CCA)\n",
    "### The following is implemented on a 12-Class publicly available SSVEP EEG Dataset\n",
    "\n",
    "<img src=\"../images/12_classSSVEP.png\">\n",
    "\n",
    "#### Dataset URL: \n",
    "https://github.com/mnakanishi/12JFPM_SSVEP/tree/master/data\n",
    "\n",
    "#### Dataset Paper:\n",
    "Masaki Nakanishi, Yijun Wang, Yu-Te Wang and Tzyy-Ping Jung, \n",
    "\"A Comparison Study of Canonical Correlation Analysis Based Methods for Detecting Steady-State Visual Evoked Potentials,\" \n",
    "PLoS One, vol.10, no.10, e140703, 2015. \n",
    "\n",
    "#### Implementation:\n",
    "Note: Following implementation is an asynchronous SSVEP BCI using CCA classification for 1 second data length\n",
    "\n",
    "Aravind Ravi | eBionics Lab | University of Waterloo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scripts import ssvep_utils as su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canonical Correlation Analysis (CCA)\n",
    "$$\\DeclareMathOperator*{\\argmax}{argmax}$$\n",
    "\n",
    "Consider two multidimensional variables $X$, $Y$ where $X$ refers to the set of multi-channel EEG data and $Y$ refers to the set of reference signals of the same length as $X$. The linear combinations of $X$ and $Y$ are given as $x = X'W_{x}$ and $y = Y'W_{y}$. CCA finds the weights, $W_{x}$ and $W_{y}$ that maximize the correlation between $x$ and $y$ by solving (1). The maximum of $\\rho$ with respect to $W_{x}$ and $W_{y}$ is the maximum correlation.\n",
    "\n",
    "$$\\max_{W_{x},W_{y}} \\rho(x,y) = \\frac{\\mathbb{E}{[W_{x}'XY'W_{y}]}}{\\sqrt{\\mathbb{E}{[W_{x}'XX'W_{x}]}\\mathbb{E}{[W_{y}'YY'W_{y}]}}}$$\n",
    "\n",
    "The reference signals $Y_{n}$  are defined as:\n",
    "\n",
    "$$Y_{n} = \\begin{bmatrix} \\sin({2 \\pi f_{n}t}) \\\\ \\cos({2 \\pi f_{n}t}) \\\\ \\vdots \\\\ \\sin({4 \\pi  f_{n}t}) \\\\ \\cos({4 \\pi  f_{n}t}) \\end{bmatrix},t = \\begin{bmatrix} \n",
    "    \\frac{1}{f_{s}}\n",
    "    \\frac{2}{f_{s}}\n",
    "    \\dots\n",
    "    \\frac{N_{s}}{f_{s}}\n",
    "    \\end{bmatrix}$$\n",
    "    \n",
    "where $Y_{n} \\in \\mathbb{R}^{2 N_{h} \\times N_{s}} $, $f_{n}$ is the stimulation frequency, $f_{s}$ is the sampling frequency, $N_{s}$ is number of samples, and $N_{h}$ is the number of harmonics. Here, $N_{h}=2$. The canonical correlation features $\\rho_{f_{i}}$, where $i = 1,2,...,7$ are extracted for each segment of the EEG data, and the output class $C$ for a given sample can be determined as: $C = \\argmax (\\rho_{f_{i}})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath('../data')\n",
    "all_segment_data = dict()\n",
    "all_acc = list()\n",
    "window_len = 1\n",
    "shift_len = 1\n",
    "sample_rate = 256\n",
    "duration = int(window_len*sample_rate)\n",
    "flicker_freq = np.array([9.25, 11.25, 13.25, 9.75, 11.75, 13.75, \n",
    "                       10.25, 12.25, 14.25, 10.75, 12.75, 14.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cca_reference_signals(data_len, target_freq, sampling_rate):\n",
    "    reference_signals = []\n",
    "    t = np.arange(0, (data_len/(sampling_rate)), step=1.0/(sampling_rate))\n",
    "    reference_signals.append(np.sin(np.pi*2*target_freq*t))\n",
    "    reference_signals.append(np.cos(np.pi*2*target_freq*t))\n",
    "    reference_signals.append(np.sin(np.pi*4*target_freq*t))\n",
    "    reference_signals.append(np.cos(np.pi*4*target_freq*t))\n",
    "    reference_signals = np.array(reference_signals)\n",
    "    \n",
    "    return reference_signals\n",
    "\n",
    "def find_correlation(n_components, np_buffer, freq):\n",
    "    cca = CCA(n_components)\n",
    "    corr = np.zeros(n_components)\n",
    "    result = np.zeros(freq.shape[0])\n",
    "    for freq_idx in range(0,freq.shape[0]):\n",
    "        cca.fit(np_buffer.T,np.squeeze(freq[freq_idx, :, :]).T)\n",
    "        O1_a,O1_b = cca.transform(np_buffer.T, np.squeeze(freq[freq_idx, :, :]).T)\n",
    "        ind_val = 0\n",
    "        for ind_val in range(0,n_components):\n",
    "            corr[ind_val] = np.corrcoef(O1_a[: ,ind_val], O1_b[:, ind_val])[0 ,1]\n",
    "            result[freq_idx] = np.max(corr)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def cca_classify(segmented_data, reference_templates):\n",
    "    predicted_class = []\n",
    "    labels = []\n",
    "    for target in range(0, segmented_data.shape[0]):\n",
    "        for trial in range(0, segmented_data.shape[2]):\n",
    "            for segment in range(0, segmented_data.shape[3]):\n",
    "                labels.append(target)\n",
    "                result = find_correlation(1, segmented_data[target, :, trial, segment, :], \n",
    "                                      reference_templates)\n",
    "                predicted_class.append(np.argmax(result)+1)\n",
    "    labels = np.array(labels)+1\n",
    "    predicted_class = np.array(predicted_class)\n",
    "\n",
    "    return labels, predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset, filter and segment epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in np.arange(0, 10):\n",
    "    dataset = sio.loadmat(f'{data_path}/s{subject+1}.mat')\n",
    "    eeg = np.array(dataset['eeg'], dtype='float32')\n",
    "    \n",
    "    num_classes = eeg.shape[0]\n",
    "    n_ch = eeg.shape[1]\n",
    "    total_trial_len = eeg.shape[2]\n",
    "    num_trials = eeg.shape[3]\n",
    "    \n",
    "    filtered_data = su.get_filtered_eeg(eeg, 6, 80, 4, sample_rate)\n",
    "    all_segment_data[f's{subject+1}'] = su.get_segmented_epochs(filtered_data, window_len, \n",
    "                                                           shift_len, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the required sinusoidal templates for the given 12-class SSVEP classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_templates = []\n",
    "for fr in range(0, len(flicker_freq)):\n",
    "    reference_templates.append(get_cca_reference_signals(duration, flicker_freq[fr], sample_rate))\n",
    "reference_templates = np.array(reference_templates, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform CCA on the segmented epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s1, Accuracy: 29.166666666666668 %\n",
      "Subject: s2, Accuracy: 26.25 %\n",
      "Subject: s3, Accuracy: 59.44444444444444 %\n",
      "Subject: s4, Accuracy: 80.27777777777779 %\n",
      "Subject: s5, Accuracy: 52.361111111111114 %\n",
      "Subject: s6, Accuracy: 87.22222222222223 %\n",
      "Subject: s7, Accuracy: 69.16666666666667 %\n",
      "Subject: s8, Accuracy: 96.66666666666667 %\n",
      "Subject: s9, Accuracy: 66.38888888888889 %\n",
      "Subject: s10, Accuracy: 65.27777777777779 %\n"
     ]
    }
   ],
   "source": [
    "for subject in all_segment_data.keys():\n",
    "    labels, predicted_class = cca_classify(all_segment_data[subject], reference_templates)\n",
    "    c_mat = confusion_matrix(labels, predicted_class)\n",
    "    accuracy = np.divide(np.trace(c_mat), np.sum(np.sum(c_mat)))\n",
    "    all_acc.append(accuracy)\n",
    "    print(f'Subject: {subject}, Accuracy: {accuracy*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy Across Subjects: 63.22222222222222 %, std: 21.665580457103147 %\n"
     ]
    }
   ],
   "source": [
    "all_acc = np.array(all_acc)\n",
    "print(f'Overall Accuracy Across Subjects: {np.mean(all_acc)*100} %, std: {np.std(all_acc)*100} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "783px",
    "left": "1528px",
    "right": "20px",
    "top": "115px",
    "width": "387px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
